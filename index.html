<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="SJTU | PhD Candidate">
<meta name="keywords" content=".">
<meta property="og:type" content="website">
<meta property="og:title" content="保持动力">
<meta property="og:url" content="jrunning.cn/index.html">
<meta property="og:site_name" content="保持动力">
<meta property="og:description" content="SJTU | PhD Candidate">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="保持动力">
<meta name="twitter:description" content="SJTU | PhD Candidate">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="jrunning.cn/"/>





  <title>保持动力</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">保持动力</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">寻找稳固的自我</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-study">
          <a href="/study/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br />
            
            论文
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-nav">
          <a href="/nav/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-map"></i> <br />
            
            导航
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="jrunning.cn/2018/12/27/paper-literature-review-ai-ipa/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiang Shuo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="保持动力">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/27/paper-literature-review-ai-ipa/" itemprop="url">论文笔记 | 文献综述：知产数据分析的人工智能方法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-27T21:53:00+08:00">
                2018-12-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/paper/" itemprop="url" rel="index">
                    <span itemprop="name">paper</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="知产分析的前沿：关于知产数据分析的人工智能方法综述"><a href="#知产分析的前沿：关于知产数据分析的人工智能方法综述" class="headerlink" title="知产分析的前沿：关于知产数据分析的人工智能方法综述"></a><strong>知产分析的前沿：关于知产数据分析的人工智能方法综述</strong></h2><blockquote>
<p>Aristodemou L, Tietze F. <strong>The state-of-the-art on Intellectual Property Analytics (IPA): A literature review on artificial intelligence, machine learning and deep learning methods for analysing intellectual property (IP) data</strong>[J]. World Patent Information, 2018, 55: 37-51.</p>
</blockquote>
<h3 id="★-思维导图"><a href="#★-思维导图" class="headerlink" title="★ 思维导图"></a><strong>★ 思维导图</strong></h3><p><img src="http://static.zybuluo.com/jiangshuo1016/tutnrmspk453jg59f5nqu7da/IPA.png" alt="IPA.png-104.5kB"></p>
<h3 id="★-摘要"><a href="#★-摘要" class="headerlink" title="★ 摘要"></a><strong>★ 摘要</strong></h3><p>大数据在制造和操作方面的所有领域都变得越来越容易获得，这为做出更好的决策以及寻找下一代创新科技提供了机会。近来，专利分析领域有很大的发展，它是关于分析大量专利信息以发现科技趋势的科学。我们定义知产分析（IPA）为分析大规模知产信息的数据科学，以发现其中的关系、趋势和模式从而为决策提供帮助。本文主要讨论的是知产分析所使用的方法，比如人工智能方法，机器学习以及深度学习方法。文献综述以叙述的方式展开，我们通过阅读57篇文献，展示了最前沿水平的知产分析方法。<strong>这些文章可以被分为四类：知识管理、技术管理、经济价值以及信息的抽取和有效管理。</strong></p>
<h3 id="★-研究背景"><a href="#★-研究背景" class="headerlink" title="★ 研究背景"></a><strong>★ 研究背景</strong></h3><ul>
<li>大数据的好处：更好的决策和技术发展。</li>
<li>过去二十年，专利分析发展迅速。专利数据库被认为是世界上最大的科技信息数据库。</li>
<li>本文的作者在这篇文章之前，还曾探索了专利分析的未来趋势，归纳了11种专利分析里被运用地比较频繁的技术。</li>
<li>专利分析可以帮助完成决策过程，或提供决策支持。</li>
</ul>
<h3 id="★-知产分析定义"><a href="#★-知产分析定义" class="headerlink" title="★ 知产分析定义"></a><strong>★ 知产分析定义</strong></h3><blockquote>
<p><strong>Intellectual Property Analytics (IPA)</strong> is the data science of analysing large amount of intellectual property information, to discover relationships, trends and patterns in the data for decisiong making. It is a multidisciplinary approach that makes use of mathematics, statistics, computer programming, and operations research to gain valuable knowledge from data, to support decision making rooted in the business context.</p>
</blockquote>
<p>知产分析是一种数据科学。它分析大规模的知识产权信息，来发现蕴含于数据中的关系、趋势以及模式，以支持决策过程。它是多学科交叉的领域，运用数学、统计学、计算机编程、运筹管理学等，从数据中获取有价值的知识，来支持商业环境中的决策制定。</p>
<p>这个定义与 <em>Patinformatics</em> 的定义是保持一致的。</p>
<h3 id="★-知产分析流程"><a href="#★-知产分析流程" class="headerlink" title="★ 知产分析流程"></a><strong>★ 知产分析流程</strong></h3><p>知产分析流程主要包含三个阶段：</p>
<ol>
<li>预处理阶段：收集数据，提取信息后清洗和准备，目的是提供高质量、高准确率和高完整度的数据。</li>
<li>处理阶段：使用各种方法分析上一步得到的数据，完成分类、聚类、识别有价值信息。</li>
<li>后处理阶段：也称为「发现知识」，结果和信息进行可视化及评估，以支持决策。</li>
</ol>
<p>这篇文献聚焦的是第二阶段与第三阶段，尤其是用于分析数据的算法。</p>
<p>其它还有一些文献中，认为专利分析过程是一个目标驱动的过程，包含有检索任务（质量、有效性、侵权、公司调研、技术调研）、分析任务（商业价值评估、技术评估、技术建议）、监测任务（早期监测、技术监测、公司监测、单一专利监测）。</p>
<h3 id="★-文献综述的方法"><a href="#★-文献综述的方法" class="headerlink" title="★ 文献综述的方法"></a><strong>★ 文献综述的方法</strong></h3><p><img src="http://static.zybuluo.com/jiangshuo1016/pyagpevzgwgbhug5a1pb9a2t/image_1cvk6555l17nt1kd112qprvae71s.png" alt="image_1cvk6555l17nt1kd112qprvae71s.png-168.4kB"></p>
<h3 id="★-著录信息分析结果"><a href="#★-著录信息分析结果" class="headerlink" title="★ 著录信息分析结果"></a><strong>★ 著录信息分析结果</strong></h3><p><img src="http://static.zybuluo.com/jiangshuo1016/escu3cmvr96rwjtgalp4o76v/image_1cvk676gr1oq0edb1hvv1ebefln19.png" alt="image_1cvk676gr1oq0edb1hvv1ebefln19.png-37.1kB"></p>
<p>相关文章数量，在近年较多。</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/uxop1xdwkb6vfeoeukawsilx/image_1cvk69pii19u841l18neo9715ck35.png" alt="image_1cvk69pii19u841l18neo9715ck35.png-132.7kB"></p>
<p>引用次数，最高的再2017年达到153次引用。</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/mw0dm6zybs7c5ov1c1dw7sgh/image_1cvk7c628bni1dgo8d81629rkv42.png" alt="image_1cvk7c628bni1dgo8d81629rkv42.png-136kB"></p>
<p>文章发表的领域，主要是计算机科学（29%），社会科学（14%），商业管理类（14%），工程类（9%），数学类（7%）。这说明，这个领域是一个交叉学科。</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/4rlo0kkpo87z7k2oozhxmnyd/image_1cvk7efrrebg19te1c4g1cjedi54f.png" alt="image_1cvk7efrrebg19te1c4g1cjedi54f.png-52.4kB"></p>
<p>前十的机构：可以关注国立清华大学、国立交通大学、国立云林科技大学、中华大学、北京理工大学。</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/5057whao543cj5u2r3j98kvt/image_1cvk7fsi91qnf1cuqqlrti2g165f.png" alt="image_1cvk7fsi91qnf1cuqqlrti2g165f.png-35.7kB"></p>
<p>前十的国家，以亚洲国家为主（台湾、韩国、中国），其次是美国。</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/nbnzqhi7fv52l62u2h1qvmo6/image_1cvk7gt0gl1o10a31svk1t6k1d529.png" alt="image_1cvk7gt0gl1o10a31svk1t6k1d529.png-54.5kB"></p>
<p>前十的期刊。</p>
<h3 id="★-知产分析方法"><a href="#★-知产分析方法" class="headerlink" title="★ 知产分析方法"></a><strong>★ 知产分析方法</strong></h3><p>文章使用的方法集中于人工神经网络、BP算法、支持向量机、条件随机场。多数文章聚焦于分类方法，有些将聚类方法与分类方法结合。以下将方法分为四个类别说明：知识管理、技术管理、经济价值以及信息的抽取和有效管理。</p>
<h4 id="☆-知识管理"><a href="#☆-知识管理" class="headerlink" title="☆ 知识管理"></a><strong>☆ 知识管理</strong></h4><ul>
<li>【2006】Trappey等提出了一种文档分类与检索方法，基于<strong>神经网络</strong>技术，旨在帮助公司更有效地管理专利文档。</li>
<li>【2012】Trappey等提出了一种帮助公司评估专利质量（是否能应用于创新产品开发）的方法，以及发现当下前沿技术趋势。使用基于<strong>BP神经网络</strong>的方法，专利根据他们的质量分类，准确率达到85%。</li>
<li>【2013】Trappey等提出了一种基于本体的<strong>人工神经网络</strong>算法，实现知识文档的自动分类与检索，以促进新产品的创新研发。</li>
<li>【2016】Wu等提出一种自动的专利质量分析评价系统，系统基于<strong>自组织生长网络、核主成分分析以及支持向量机</strong>。</li>
<li>【2009】Lv等提出了<strong>混合最大最小模块</strong>和<strong>支持向量机</strong>的分类器，充分挖掘先验知识来增加对日本专利的学习性能。（上海交大吕宝粮老师，我上过他的神经网络课！）</li>
<li>【2012】Hido等使用一种结合<strong>文本挖掘</strong>与<strong>机器学习</strong>的方法来计算一个专利的得分，以此评估专利应用的质量。专利的得分代表了它会被专利局认可的概率。</li>
</ul>
<h4 id="☆-技术管理"><a href="#☆-技术管理" class="headerlink" title="☆ 技术管理"></a><strong>☆ 技术管理</strong></h4><p> ※ 识别技术趋势</p>
<ul>
<li>【2010】Thorleuchter等提出一种基于<strong>定量交叉影响</strong>的分析方法，使得技术影响更透明可见。它通过分析对手公司研发部门的技术影响及影响趋势，对比自己公司研发部门，来估计技术的影响。</li>
<li>【2017】Suominen等讨论了机器学习方法在工业级专利分析中的优势与限制，提出一种基于<strong>LDA</strong>全文描述符的分类，来展示工业界专利全局情况。这样一来，便可识别技术趋势以及预测未来趋势。</li>
<li>【2014】Jun等使用一种<strong>整体方法</strong>来分析发展技术领域内的已发表文章、文献、专利，来识别科学技术趋势。</li>
<li>【2017】Sun等使用一种<strong>细胞结构神经网络</strong>，以及<strong>Girvan-Newman算法</strong>，来构建技术评估的可视化地图，以展示技术领域的发展趋势。</li>
<li>【2016】Lee等使用多个专利的指标，提出一种基于<strong>全生命循环周期</strong>的技术趋势探索方法，使用了隐马尔可夫模型来估计技术在某一阶段被使用的概率。</li>
<li>【2018】Govindarajan等提出一种<strong>话题模型方法</strong>，基于LDA算法来构建工业4.0的本体领域及技术发展趋势。</li>
</ul>
<p>※ 预测技术创新</p>
<ul>
<li>【2013】Jun和Park建立了首个统计模型，使用<strong>时间序列回归方法</strong>构建了技术地图，接着用聚类的方法识别出苹果公司空缺的技术领域。然后利用社交网络，来寻找苹果公司未来的技术核心。</li>
<li>【2017】Kim和Lee提出一种预测多技术合并的方法，基于<strong>专利引用分析、依赖结构矩阵以及神经网络分析</strong>。该方法可以规划未来的技术发展以及技术合并。</li>
<li>【2009】Zhang等提出一种基于支持向量机的方法，实现预测某一领域内专利应用的数量，克服了专利内存在的稀疏问题。</li>
<li>【2016】Jun提出了一种混合聚类方法，使用<strong>降维及K-means聚类方法</strong>，<strong>基于支持向量聚类以及Silhouette度量</strong>，来完成技术预测。</li>
<li>【2018】T-G和Morales描述了一种叫「自动发现概念」的系统，结合了「预测创新的归纳逻辑编程」以及「内在动机强化学习」来发现新概念。</li>
</ul>
<p>※ 理解当前技术变化（例如技术趋同）</p>
<ul>
<li>【2017】Trappey等提出了知产分析方法，挖掘生物添加剂领域内专利的价值和评估，以支持决策以及规划战略。</li>
<li>【2016】Momeni和Rost提出了一种基于<strong>专利发展路径、k-core分析以及话题模型</strong>的方法，来识别潜在的颠覆性技术。</li>
<li>【2017】Kyebambe等提出一种技术预测方法，<strong>基于引用数据</strong>，以一年为时间单位，自动地对数据进行标签、训练学习器，实现技术合并的预测。</li>
<li>【2018】Lee等使用多个专利指标，提出一种神经网络方法在早期识别技术合并，在相关专利发表后可以立即地识别发现。</li>
<li>【2012】Jun和Lee提出一种结合<strong>统计推理与神经网络</strong>的方法，来构建技术合并预测模型。</li>
<li>【2015】Choi等提出一种基于<strong>社交网络和决策树</strong>的专利预测分析模型，以支持专利转移转让。</li>
</ul>
<h4 id="☆-知识产权的经济价值"><a href="#☆-知识产权的经济价值" class="headerlink" title="☆ 知识产权的经济价值"></a><strong>☆ 知识产权的经济价值</strong></h4><p>※ 经济的发展可以通过科技来实现。使用人工智能方法，基于不同的科技因素，来预测经济的发展。</p>
<ul>
<li>【2017】Markovic等提出一种极限学习机方法来预测GDP的增长率。</li>
<li>【2016】Lee等提出一种定量的公司表现预测模型，应用<strong>支持向量回归算法</strong>，使用金融数据和科技数据。</li>
<li>【2017】Lee等使用深度神经网络构建了公司表现预测模型，使用公司金融数据及专利指标作为观测对象。这个模型包括一个<strong>无监督学习阶段（限制玻尔兹曼机）</strong>以及一个<strong>微调阶段（反向传播算法）</strong>。</li>
<li>【2009,2010】多位学者对美国制药工业的研发进行研究，他们通过探索专利的定量指标、定性指标以及公司市场价值，得出结论：美国制药工业不应该将资源集中于某一个科技领域，而应该寻找更广阔的的机会。</li>
<li>【2010】Chen和Chang探索了公司规模、盈利及专利引用间的非线性关系。</li>
<li>【2010】Chen和Chang探索了专利HHI指数与重要科技领域或公司内相关专利的关系。</li>
<li>【2010】Bass和Kurgan通过许多不同的<strong>分类算法</strong>分析了纳米科技的专利，以识别不同因素对专利价值的影响，从而找出那些最有意义的专利。</li>
<li>【2009】Lai和Che基于<strong>神经网络</strong>，提出一种面向专利法的专利法律价值评估模型。</li>
</ul>
<h4 id="☆-信息的抽取和有效管理"><a href="#☆-信息的抽取和有效管理" class="headerlink" title="☆ 信息的抽取和有效管理"></a><strong>☆ 信息的抽取和有效管理</strong></h4><p>※ 化学名称识别抽取：包括药物名称、化合物名称，主要方法是条件随机场。<br>※ 图像的识别抽取：专利图像识别、专利图像信息抽取、CBIR。<br>※ 公共信息的有效管理（基于分类）</p>
<ul>
<li>【2014】Zhang提出一种基于<strong>多分类器融合和主动学习</strong>的方法，实现专利的分类。</li>
<li>【2015】Venugopalan和Rai提出一种基于<strong>自然语言处理</strong>的多层方法，结合<strong>支持向量机</strong>算法，实现专利数据的自动识别与分类。</li>
<li>【2015】Zhu等提出一种用户需求导向的分类方法，使用<strong>监督机器学习</strong>技术，将专利数据集分类到用户预定义的类别中。</li>
<li>【2012】Wu和Yao提出一种名为专利网络分析的方法，创建可视化网络，它可以为专利文档的检索提供自动的流程、专利关键词提取以及确定专利关键词的权重以生成b复杂的可视化专利网络。</li>
<li>【2009】Li等针对信息的重复问题，提出一种知识评估流程，使用专利引用信息，基于<strong>机器学习核方法</strong>，来对专利进行分类。</li>
<li>【2017】Trappey提出一种基于<strong>调整形式概念分析</strong>的方法，针对4G通信领域，评估专利以及发现诉讼和有争议专利之间的联系。</li>
</ul>
<h3 id="★-其它"><a href="#★-其它" class="headerlink" title="★ 其它"></a><strong>★ 其它</strong></h3><p>检索式：</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/8dmntnc89vqox5h9om5qaads/image_1cvmp6ehb1erhul2tsq1q2m1g2846.png" alt="image_1cvmp6ehb1erhul2tsq1q2m1g2846.png-336.5kB"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="jrunning.cn/2018/12/18/get-up-early/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiang Shuo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="保持动力">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/18/get-up-early/" itemprop="url">养成早起小习惯</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-18T19:10:00+08:00">
                2018-12-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/生活/" itemprop="url" rel="index">
                    <span itemprop="name">生活</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://static.zybuluo.com/jiangshuo1016/k65ioxxgqgzs02iwmbv2p843/sunrise-717816_1920.jpg" alt="sunrise-717816_1920.jpg-440.7kB"></p>
<p>在人生漫长的旅途中，我走到了博士求学这个特殊的阶段。博士这个群体，尤其是国内博士，总有人会把它与压力大、容易抑郁相挂钩。不知道这种感觉算不算焦虑，但是从暑假以来有好几次从内心觉得自己没有明确的目标，没有深远的规划，甚至没有健全的人格 。我到底为了什么而活？一次次叩问心灵却找不到答案，心里却是对自己更大的失望。我总是要求和希望自己能在各方面都表现得很好，“很好”的标准和定义却又一直在变，那么何时是个尽头呢，此时此刻，我在身边的环境中看不到明确的路径。</p>
<p>我不是一个爱抱怨的人，严格来说，我应该属于是行动派，我可以把明确的计划完成得很好，得到一个好的结果。在这博士伊始，我是彻彻底底的在挣扎着，是一种心态上的挣扎，心理上的不健康。记得在研一的时候，我跟照宇和云皓说过：“我在内心深处是很不认可自己的。”也许这与我以往的经历有关，并且到现在也没有根除，无论这期间获得过多少的赞誉。这种不认可的感觉，在最近被进一步地放大，有时甚至会影响到生活。</p>
<p>其实我很幸运，我不需要去应对很多其他博士同学要面临的家庭状况、恋爱婚姻、买房买车等压力。身边的人也许不解我的压力在哪，但是我还是真真切切地焦虑了。我认为这是由于我的欲望在膨胀，想要的越来越多，觉得其它人对我的期望越来越高。内心对自己的评估总是匹配不了我的欲望，以及自己幻想出来的他人对我的期望。而后者，严重时甚至会影响我的社交习惯。与此同时，我又会后悔于自己的一些选择，曾经的一些做法，这让内心的矛盾与冲突愈发激烈。这学期看过两次心理咨询，第二次时，咨询师对我说：<strong>你总跟优秀的人去比，也许你心里默认的那些竞争对象，他们的境遇，都是你幻想出来的呢？</strong>我有点认同，好像我总是很排斥去跟比我优秀一些的人去交流，而那些优秀很多或者是不在一个圈子里的优秀的人，我又没有这种感觉。这种感觉，也许也与内心对自己的不认可相关吧。</p>
<p>活在当下，正念冥想，专注于要做的事。是资料告诉我的关于改善这种困境的方法。小飞虫奇迹分享说：活在当下，是与其它过去的事情切掉了联系。不断地把过去的自己，别人期望中的自己，以及真实的自己相比较，这种比较也是一种联系。我觉得，让我痛苦的地方就在于此。本来给这篇记录起的标题是“从一些小习惯改变”，改变这个词有点刺眼，太强迫了，我不想再强迫自己了。让我记录这个痛苦的感觉，但是我认为我不需要去改变什么，我应该接纳自己。 </p>
<p>养成早起小习惯，是希望自己能减少让自己焦虑的机会。近来机缘巧合看到许多其它人的分享早起的感觉：早起可以让你的早上延长很多，从而更从容地应对下午与晚上。因此，我希望早起可以成为我的第一个习惯，当作是一种尝试，像当年迈开腿开始跑步一样，也别赋予它太多的意义。为了养成这个小习惯，固定一些「Morning Routing」：</p>
<ul>
<li>早上6点30前起床穿好衣服</li>
<li>刷牙洗脸时自拍一张发给母亲</li>
<li>喝一杯热水</li>
<li>出门前对着镜子微笑一下</li>
</ul>
<p>希望这会让近期的心理有所改善，让我在这<strong>人生难得清闲的时光</strong>里，找到自己舒服的状态。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="jrunning.cn/2018/12/16/study-spp-net/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiang Shuo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="保持动力">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/16/study-spp-net/" itemprop="url">学习笔记 | Spp-Net原理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-16T21:53:00+08:00">
                2018-12-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/study/" itemprop="url" rel="index">
                    <span itemprop="name">study</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Spp-Net"><a href="#Spp-Net" class="headerlink" title="Spp-Net"></a><strong>Spp-Net</strong></h2><blockquote>
<p>He K, Zhang X, Ren S, et al. <strong>Spatial pyramid pooling in deep convolutional networks for visual recognition</strong>[C]//European conference on computer vision. Springer, Cham, 2014: 346-361.</p>
</blockquote>
<h3 id="★-为什么要用Spp-Net？"><a href="#★-为什么要用Spp-Net？" class="headerlink" title="★ 为什么要用Spp-Net？"></a><strong>★ 为什么要用Spp-Net？</strong></h3><p>在此之前，所有的神经网络都是需要输入固定尺寸的图片，比如224x224(ImageNet)、32x32(LenNet)等。这样对于我们希望检测各种大小的图片的时候，需要经过crop，或者warp等一系列操作，这都在一定程度上导致图片信息的丢失和变形，限制了识别精确度。</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/7maeogbf266fzfv3guzo6otp/image_1cuspfhjf18tkgqc1muu71r9i9.png" alt="image_1cuspfhjf18tkgqc1muu71r9i9.png-57.9kB"></p>
<p>而Spp-Net中的金字塔池化层可以解决这个问题，它可以允许任意尺寸图片的输入。</p>
<h3 id="★-为什么要输入固定尺寸的图片？"><a href="#★-为什么要输入固定尺寸的图片？" class="headerlink" title="★ 为什么要输入固定尺寸的图片？"></a><strong>★ 为什么要输入固定尺寸的图片？</strong></h3><p>CNN主要包括两部分：卷积层和全连接层。实际上，卷积层不需要固定尺寸的图像，可以生成任意尺寸的特征图，而全连接层需要输入固定尺寸。因为它要把输入的所有像素点连接起来,需要指定输入层神经元个数和输出层神经元个数，所以需要规定输入的feature的大小。<strong>因此，固定尺寸的约束只来自于全连接层，而全连接层处于网络比较深的层级。</strong> </p>
<h3 id="★-Spp-Net的结构"><a href="#★-Spp-Net的结构" class="headerlink" title="★ Spp-Net的结构"></a><strong>★ Spp-Net的结构</strong></h3><p><img src="http://static.zybuluo.com/jiangshuo1016/e32kwhmeyq8b1d8urebssiqc/image_1cusqe3ti5s4cs411su120f1v1em.png" alt="image_1cusqe3ti5s4cs411su120f1v1em.png-74kB"></p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/lnjoas5cqf9cbbb4e74zxyuw/image_1cusqfefhhe2c3ms2inv8jp13.png" alt="image_1cusqfefhhe2c3ms2inv8jp13.png-49.6kB"></p>
<p>核心就在于全连接前增加了金字塔池化层，它与之前Run-Length及Fisher-Vector提到的金字塔方法很类似。黑色图片代表卷积之后的特征图，接着我们以不同大小的块来提取特征，分别是4x4，2x2，1x1，将这三张网格放到下面这张特征图上，就可以得到16+4+1=21种不同的块(Spatial bins)，我们从这21个块中，每个块提取出一个特征，这样刚好就是我们要提取的21维特征向量。这种以不同的大小格子的组合方式来池化的过程就是空间金字塔池化(SPP)。比如，要进行空间金字塔最大池化，其实就是从这21个图片块中，分别计算每个块的最大值，从而得到一个输出单元，最终得到一个21维特征的输出。这个向量维度固定之后，后面的全链接层就可以固定了，因为神经元个数固定下来了，就是这个向量维度。</p>
<h3 id="★-实验效果"><a href="#★-实验效果" class="headerlink" title="★ 实验效果"></a><strong>★ 实验效果</strong></h3><ol>
<li>spp-pooling层能提升准确率。</li>
<li>multi-size training能进一步提升准确率。</li>
<li>整张照片（不管size多少）比单个照片中的一个crop作为输入能提升准确率。</li>
</ol>
<p><strong>Reference：</strong></p>
<ol>
<li><a href="https://blog.csdn.net/v1_vivian/article/details/73275259" target="_blank" rel="noopener">https://blog.csdn.net/v1_vivian/article/details/73275259</a></li>
<li><a href="https://blog.csdn.net/helloR123/article/details/75692461" target="_blank" rel="noopener">https://blog.csdn.net/helloR123/article/details/75692461</a></li>
<li><a href="https://blog.csdn.net/zhangjunhit/article/details/53909548" target="_blank" rel="noopener">https://blog.csdn.net/zhangjunhit/article/details/53909548</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="jrunning.cn/2018/12/15/paper-comparing-sift-and/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiang Shuo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="保持动力">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/15/paper-comparing-sift-and/" itemprop="url">论文笔记 | 专利图像表示：SIFT vs SURF</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-15T11:09:00+08:00">
                2018-12-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/paper/" itemprop="url" rel="index">
                    <span itemprop="name">paper</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="比较SIFT与SURF在专利图像上的性能"><a href="#比较SIFT与SURF在专利图像上的性能" class="headerlink" title="比较SIFT与SURF在专利图像上的性能"></a><strong>比较SIFT与SURF在专利图像上的性能</strong></h2><blockquote>
<p>Lindqvist C. <strong>Comparing SIFT and SURF: Performance on patent drawings</strong>[D]. 2017.</p>
</blockquote>
<p>这是来自瑞典乌普萨拉大学学生的一篇硕士论文，关于专利图像表示，比较SIFT与SURF。从SURF的介绍中，我们知道SURF与SIFT算法相似，SIFT算法比较稳定，检测特征点更多，但是复杂度较高，而SURF要运算简单，效率高，运算时间短一点。本文的作者想通过实验，在文档图像上进行验证。</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/ch4w0ufumohgr9a8ro09m27n/image_1cunslriu1it71bq114j2a61s9k15.png" alt="image_1cunslriu1it71bq114j2a61s9k15.png-56.6kB"></p>
<h3 id="★-摘要"><a href="#★-摘要" class="headerlink" title="★ 摘要"></a><strong>★ 摘要</strong></h3><p>近年来，有研究发现人们可以利用专利中的图像来组织大规模的专利，这对于减少浏览专利所花费的时间和工作量是极有帮助的。研究提出了一个系统，可以通过CBIR技术寻找和比较特定的图像。关于CBIR技术，有非常多可以使用的算法，而它们各有各的优势。这篇论文测试了两种关于专利图像表示的算法：<a href="https://blog.csdn.net/songzitea/article/details/13627823" target="_blank" rel="noopener">SIFT</a>和<a href="https://blog.csdn.net/songzitea/article/details/16986423" target="_blank" rel="noopener">SURF</a>。</p>
<p>实验显示，当我们仅看前20个算法相关结果时，可以检索到3-4个实际相关的图像，当目标范围更大时，检索到的相关图像可能会更多。这意味着可能可以仅使用一个特定专利文档的图像来找到多个相关专利。</p>
<h3 id="★-结论"><a href="#★-结论" class="headerlink" title="★ 结论"></a><strong>★ 结论</strong></h3><p>本文的工作首先是收集数据，其次是选择合适的系统，不仅要保证速度和准确率，而且最好有开源代码进行调整。最终，选择了SURF和SIFT。使用它们进行检索时，前20个相关的结果中有3-4个是实际相关的，查看这3-4个实际相关的图像归属，可以找到1-2个相关的专利文档。但是，是否可以推广到大规模的知识产权领域，有待进一步的验证。</p>
<p>重复上述的过程，可以找到相似图像。然而花费的时间与找到的数量，相比于使用关键词检索再一一浏览，有何差异，这需要进一步的评估。</p>
<p>SIFT和SURF都可以有效地处理这一问题，总体相差不大，见下表所示。如果考虑时间，SURF要优于SIFT。相反，如果不考虑时间，SIFT的准确率会更高一些。所以具体如何选择，需要根据不同的环境来考虑。</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/oz7d28n2brunpoyaof4dk5ap/image_1cunsn25jvhqg1412hi7p0131j1l.png" alt="image_1cunsn25jvhqg1412hi7p0131j1l.png-168.3kB"></p>
<h3 id="★-其他"><a href="#★-其他" class="headerlink" title="★ 其他"></a><strong>★ 其他</strong></h3><ul>
<li>CBIR常用的图像数据库：<a href="https://sites.google.com/site/dctresearch/Home/content-based-image-retrieval" target="_blank" rel="noopener"><strong>The COREL Database</strong></a>，包含了10800张图像，80个类别。</li>
<li>本文中使用了<a href="http://www.cs.ubc.ca/research/flann/uploads/FLANN/flann_manual-1.8.4.pdf" target="_blank" rel="noopener"><strong>FLANN库</strong></a>来匹配特征。FLANN库全称是Fast Library for Approximate Nearest Neighbors，它是目前最完整的（近似）最近邻开源库。不但实现了一系列查找算法，还包含了一种自动选取最快算法的机制。</li>
<li>使用不同的数据集（系统）进行评估，举例：PatMedia，PATSEEK；本文中用了TREC的评估标准。</li>
</ul>
<h3 id="★-自己的收获"><a href="#★-自己的收获" class="headerlink" title="★ 自己的收获"></a><strong>★ 自己的收获</strong></h3><ol>
<li>对SIFT和SURF的比较有了感性的认识，再文档图像的应用中，总体差别不大。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="jrunning.cn/2018/12/14/paper-what-is-the-right/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiang Shuo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="保持动力">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/14/paper-what-is-the-right/" itemprop="url">论文笔记 | 文档图像表示：三种方法比较</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-14T21:53:00+08:00">
                2018-12-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/paper/" itemprop="url" rel="index">
                    <span itemprop="name">paper</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="文档图像的正确表示方式"><a href="#文档图像的正确表示方式" class="headerlink" title="文档图像的正确表示方式"></a><strong>文档图像的正确表示方式</strong></h2><blockquote>
<p>Csurka G, Larlus D, Gordo A, et al. <strong>What is the right way to represent document images?</strong>[J]. arXiv preprint arXiv:1603.01076, 2016.</p>
</blockquote>
<p>在前几天读过的一篇专利图像分类的论文中（<a href="http://jacobrun.com/2018/12/04/2018-12-4-paper-document-image-classification/" target="_blank" rel="noopener">笔记链接</a>），讲到了两种基于浅层特征的图像表示方法：Run Length和Fisher Vector。本文从更全面的视角，比较了浅层特征图像表示方法、深层特征图像表示方法（基于卷积神经网络）以及基于前两类特征的混合表示方法。</p>
<h3 id="★-摘要"><a href="#★-摘要" class="headerlink" title="★ 摘要"></a><strong>★ 摘要</strong></h3><p>本文探讨了基于视觉特征的图像表示方法，通过广泛的实验研究对三种表示方法进行了比较：</p>
<ul>
<li>传统浅层特征：Run Length及Fisher Vector</li>
<li>深层特征：基于卷积神经网络的表示</li>
<li>从混合结构中提取的特征</li>
</ul>
<p>通过不同的任务（分类、聚类及检索）、不同的情境（领域迁移）、使用不同的数据集对这些特征表示方法进行了评估。<strong>结果表明：在没有领域迁移的情况下，即新任务与训练模型的任务较为接近时，深层特征表现较好；而在领域范围较大或有领域迁移的情况下，浅层特征Fisher Vector表现较好。</strong></p>
<h3 id="★-引言"><a href="#★-引言" class="headerlink" title="★ 引言"></a><strong>★ 引言</strong></h3><p>文档图像的理解与表示，通常有三个切入点线索：视觉线索、结构线索、文本线索。视觉线索展现的是一个图片的整体形貌，通过“整体一瞥”的方式来区分图片。结构线索捕获文档不同部分之间的关系，比如布局分析等。文本线索是从文档中获取文本信息，其中往往包括了语义信息。</p>
<p>同时使用三种线索会得到最好的效果，然而获取结构线索及语义线索的计算代价很大，在大规模领域里不适用。比如结构线索需要对文档布局进行分析，文本线索需要对整个文档执行OCR，它们都慢而易错。而且，这两种线索往往都限定在特定的领域，不具备迁移性。</p>
<p>视觉特征更一般化而且往往可以很快速地获得，因此在文档理解工作中被大量使用，有时再将另外两类信息结合进去。最近，深度学习技术被用于建立文档的视觉表示，在分类和检索任务中取得了比传统浅层特征、手工特征等更好的效果。但是深度学习对于文档图像的表示，还残留了两个问题至今没有解决：对于给定的任务与数据集，深度特征在所有的案例上都比浅层特征要好吗？它对于领域迁移、任务迁移以及数据集迁移，表现的都更好吗？</p>
<p>此外，也有研究提出了将深度表示模型与浅层特征结合，在浅层特征的顶层加上深度表示特征，旨在结合两者的优点。</p>
<h3 id="★-相关工作"><a href="#★-相关工作" class="headerlink" title="★ 相关工作"></a><strong>★ 相关工作</strong></h3><p>传统视觉特征是基于图像像素的简单统计规律。更详尽的浅层特征表示例如RunLength，结合金字塔方法，对于一些任务有更好的准确性。受自然图像表示的启发，bag-of-visual-words（BoV）或Fisher Vector表示方法，它们基于SIFT或SURF描述符，具有更好的泛化能力。</p>
<p>近期，基于CNN的表示方法，在分类和检索的性能上要好于BoV。深度特征的特点是端到端的学习，这意味着特征结构和预测被合并到同一个步骤中。也就是说，特征以及分类器被联合学习，不能被分开了。这种表示方法被大范围地证明要好于浅层特征，但是它们往往针对特定领域，对于通用的文档图像表示还没有被详细研究。而且训练的速度非常慢。</p>
<p>混合CNN以及FV的表示方法在近期被提出，这种方法被证明有较好的迁移性，但是在文档图像中还没有得到应用。</p>
<h3 id="★-文档图像特征表示"><a href="#★-文档图像特征表示" class="headerlink" title="★ 文档图像特征表示"></a><strong>★ 文档图像特征表示</strong></h3><h4 id="☆-Run-Length"><a href="#☆-Run-Length" class="headerlink" title="☆ Run Length"></a><strong>☆ Run Length</strong></h4><blockquote>
<p>Chan Y K, Chang C C. <strong>Image matching using run-length feature</strong>[J]. Pattern Recognition Letters, 2001, 22(5): 447-455.</p>
</blockquote>
<p>具体细节理解可以参见：<a href="http://jacobrun.com/2018/12/04/2018-12-4-paper-document-image-classification/" target="_blank" rel="noopener">笔记链接</a></p>
<h4 id="☆-Fisher-Vector"><a href="#☆-Fisher-Vector" class="headerlink" title="☆ Fisher Vector"></a><strong>☆ Fisher Vector</strong></h4><blockquote>
<p>Perronnin F, Dance C. <strong>Fisher kernels on visual vocabularies for image categorization</strong>[C]//2007 IEEE conference on computer vision and pattern recognition. IEEE, 2007: 1-8.</p>
</blockquote>
<p><img src="http://static.zybuluo.com/jiangshuo1016/sy5qgq2413g74qp75fz92j4w/QQ%E6%88%AA%E5%9B%BE20181213102949.png" alt="QQ截图20181213102949.png-57.6kB"></p>
<p>FV可以看作是BoV的扩展，BoV仅仅使用0阶统计规律，而FV编码了更高阶的信息。与BoV相似，FV依赖于中间的表示：视觉词汇表，它可以被视作描述图像中低阶描述符排布的概率密度函数。我们使用高斯混合模型（GMM）来表示密度。</p>
<p>对于一个核函数，有：</p>
<script type="math/tex; mode=display">K\left(X_{i},X_{j}\right)=\left[\Gamma_{\lambda}\left(I\right)\right]^{\top}\left[\Gamma_{\lambda}\left(J\right)\right]</script><p>这个$\Gamma_{\lambda}\left(I\right)$就是Fisher Kernel核函数的表示方法，即Fisher Vector，它是由Fisher Score归一化得到的。核函数需要满足：$K\left(X_{i},X_{i}\right)=1$，因此对Fisher Score需要进行归一化，形式如下：</p>
<script type="math/tex; mode=display">\Gamma_{\lambda}\left(I\right)=F_{\lambda}^{ -\frac{1}{2} }G_{\lambda}\left(I\right)</script><p>其中，$F_{\lambda}$是Fisher信息矩阵，$G_{\lambda}$是Fisher Score，定义：</p>
<script type="math/tex; mode=display">G_{\lambda}\left(I\right)=\frac{1}{T}\sum_{t=1}^{T}\nabla_{\lambda}\log\left\{ \sum_{n=1}^{N}\omega_{n}p\left(x_{t}\mid\mu_{n},{\scriptstyle \sum_{n}}\right)\right\}</script><p>这里，$X_{I}=\left\{ x_{t}\right\} _{t=1}^{T}$是从图形$I$中提取的低维特征，特征间独立同分布，服从于分布$p$，是一个GMM。$\mu_{n}$和$\sum_{n}$是均值和协方差，都是GMM的模型参数，$\omega_{n}$是GMM中第$n$个量的权重。这个$\log$似然函数对$\lambda$的梯度，描述了参数$\lambda$在$p$生成特征点集合$X$的过程中如何作用，所以这个Fisher Score中也包含了GMM生成$X$的过程中的一些结构化的信息。</p>
<p>Fisher信息矩阵，是用来作归一化的，其计算方法为：</p>
<script type="math/tex; mode=display">F_{\lambda}=G_{\lambda}G_{\lambda}^{\top}</script><p>分别对$G_{\lambda}$求关于均值与协方差的梯度，我们可以得到：</p>
<script type="math/tex; mode=display">\Gamma_{ \mu_{n}^{d} }\left(I\right)=\frac{1}{ T\sqrt{ \omega_{n} } }\sum_{t=1}^{T}g_{n}\left(x_{t}\right)\left(\frac{ x_{t}^{d}-\mu_{n}^{d} } { s_{n}^{d} }\right)</script><script type="math/tex; mode=display">\Gamma_{ s_{n}^{d} }\left(I\right)=\frac{1}{ T\sqrt{ 2\omega_{n} } }\sum_{t=1}^{T}g_{n}\left(x_{t}\right)\left[\frac{ \left(x_{t}^{d}-\mu_{n}^{d}\right)^{2} }{ \left(s_{n}^{d}\right)^{2} }-1\right]</script><p>其中，${\scriptstyle g_{n}\left(x_{t}\right)}=\frac{ {\scriptstyle \omega_{n} } {\scriptstyle p\left({\scriptstyle x\mid\mu_{n},{\scriptstyle {\scriptscriptstyle \sum}_{n} } }\right)} } { { \scriptstyle \sum_{j=1}^{N}\omega_{j}p\left(x\mid\mu_{j},{\scriptstyle {\scriptscriptstyle \sum_{j} } }\right)} }$，$s_n^d$是$\sum_n$的对角线元素。联合$\Gamma_{\mu_{n}^{d} }\left(I\right),\Gamma_{s_{n}^{d} }\left(I\right)$以及$\Gamma_{\lambda}\left(I\right)$，最终得到的特征一共是$2ND$维，$D$是低维特征$x_t$的维度。然后对最终的$2ND$维特征向量进行l2范数规范化，获得最终的Fisher Vector。</p>
<p><strong>可以看到，$D$维向量$x_t$中的每一个值，都与均值和方差做运算，并加上权重，Fisher Vector中包含了原特征向量每一维的值，并且包含了生成式建模过程的结构性信息，对图片的表达更加细致。</strong></p>
<h4 id="☆-卷积神经网络"><a href="#☆-卷积神经网络" class="headerlink" title="☆ 卷积神经网络"></a><strong>☆ 卷积神经网络</strong></h4><p>卷积神经网络，在端到端的模式下，通过多个线性层或非线性层的联合学习，实现解决某一特殊任务。<a href="https://blog.csdn.net/langb2014/article/details/53019350" target="_blank" rel="noopener">端到端</a>，指的是输入是原始数据，输出是最后的结果，原来输入端不是直接的原始数据，而是在原始数据中提取的特征。其好处是：通过缩减人工预处理和后续处理，尽可能使模型从原始输入到最终输出，给模型更多可以根据数据自动调节的空间，增加模型的整体契合度。</p>
<p>卷积神经网络，通常包括卷积层、全连接层以及作为最终层的Softmax层。一个前馈的神经网络可以被视作是一系列嵌套的函数：</p>
<script type="math/tex; mode=display">{\displaystyle F\left(x\right)=F_{L}\left(\ldots F_{2}\left(F_{1}\left(x,W_{1}\right),W_{2}\right),\ldots,W_{L}\right)}</script><p><img src="http://static.zybuluo.com/jiangshuo1016/2k8in3w5o9xyb9txm0bk71u6/image_1cuj5qe0f1ti81l9livnol1c68l.png" alt="image_1cuj5qe0f1ti81l9livnol1c68l.png-158.9kB"></p>
<blockquote>
<p>关于卷积神经网络细节介绍，可以参考这份PPT：<a href="https://wenku.baidu.com/view/b0b2bf5800f69e3143323968011ca300a6c3f68f.html" target="_blank" rel="noopener">Introduction to CNNs and AlexNet</a></p>
</blockquote>
<p>尽管卷积神经网络在1990年左右就被提出（LeNet），但是随着最近它被广泛成功应用于图像识别竞赛，越来越多不同结构的卷积神经网络被提出。</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/sc4tiy8swqbuvv19efulyf53/QQ%E6%88%AA%E5%9B%BE20181213150616.png" alt="QQ截图20181213150616.png-226.7kB"></p>
<p>本文聚焦于两种流行的CNN框架：$AlexNet$（左上）和$GoogLeNet$（左下）。</p>
<p>※$AlexNet$：<a href="https://blog.csdn.net/qq_24695385/article/details/80368618" target="_blank" rel="noopener">详细解读</a><br>※$GoogLeNet$：<a href="https://blog.csdn.net/cdknight_happy/article/details/79247280" target="_blank" rel="noopener">详细解读</a></p>
<h4 id="☆-混合描述符"><a href="#☆-混合描述符" class="headerlink" title="☆ 混合描述符"></a><strong>☆ 混合描述符</strong></h4><blockquote>
<p>Perronnin F, Larlus D. <strong>Fisher vectors meet neural networks: A hybrid classification architecture</strong>[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 3743-3752.</p>
</blockquote>
<p><img src="http://static.zybuluo.com/jiangshuo1016/h5fws7ov8h7zjqb5s7kbcbs9/QQ%E6%88%AA%E5%9B%BE20181213161231.png" alt="QQ截图20181213161231.png-64.8kB"></p>
<p>混合描述符表示结合了FV的无监督部分以及CNN的有监督部分，前半部分照搬上文讲解的FV特征，后面通过L-1个全连接层以及最终的softmax层输出。同样的，前面的无监督部分也可以使用RL来表示。</p>
<h3 id="★-训练"><a href="#★-训练" class="headerlink" title="★ 训练"></a><strong>★ 训练</strong></h3><h4 id="☆-为相同的任务训练"><a href="#☆-为相同的任务训练" class="headerlink" title="☆ 为相同的任务训练"></a><strong>☆ 为相同的任务训练</strong></h4><p>RL并不需要任何的训练，所有的参数都是预先定义的，因而它与数据集是无关的。FV需要一个通过无监督学习（通过对数据集聚类局部特征）得到的视觉码表，此外它不需要依赖任何数据，而且与任务是独立的。为了解决分类问题，文档图像特征以及文档标签被用于训练分类器。在我们的所有实验中，均使用线性SVM分类器，连接在RL或FV特征的上面。</p>
<p>不同于RL与FV，CNN是一种深度学习方法，特征提取步骤和分类任务是用同一个架构来完成的。我们将选择AlexNet和GoogLeNet作为结构，使用交叉熵作为损失函数通过SGD（随机梯度下降法）进行优化，分别训练两个网络。此外，还使用了dropout以防止过拟合。</p>
<p>而混合表示的训练，就是以上两种情况的结合。</p>
<h4 id="☆-为不同的任务训练"><a href="#☆-为不同的任务训练" class="headerlink" title="☆ 为不同的任务训练"></a><strong>☆ 为不同的任务训练</strong></h4><p>RL与FV，描述符可以直接地被应用于其它的任务，唯一需要做的就是给它一个好的排序/预测/分类器。而对于CNN而言，除了直接端到端训练以完成既定任务以外，还可以单独地作为特征提取器来使用，深度网络往往可以提取更复杂的特征以及语义信息。这样一来，CNN也可以像RL与FV那样，后接其它的排序/预测/分类器，完成不同的任务。在CNN中，我们从不同深度的操作层中提取出特征进行实验，以对比效果。</p>
<p>本文中，我们通过一系列任务进行定量实验，包括：图像分类、图像检索、目标检测以及动作识别。它们都可以被泛化到文档图像中。</p>
<h3 id="★-评估"><a href="#★-评估" class="headerlink" title="★ 评估"></a><strong>★ 评估</strong></h3><h4 id="☆-数据集"><a href="#☆-数据集" class="headerlink" title="☆ 数据集"></a><strong>☆ 数据集</strong></h4><p><img src="http://static.zybuluo.com/jiangshuo1016/uf19o63vh0gjkeoc45ixerls/QQ%E6%88%AA%E5%9B%BE20181213170316.png" alt="QQ截图20181213170316.png-57.9kB"></p>
<p>本文一共使用了7个数据集，前4个是公开数据集，后3个是内部数据集。</p>
<p>※RVL-CDIP：共有400000幅带标签的图片，分为16类：信件、备忘录、邮件等等。<br>※NIST：共有5590幅图片，分为12类的税表。<br>※MARG：共有1553个文档，每个文档是医学杂志的封面，分为9类布局。<br>※CLEF-IP：38081个专利图像，分为9个类别：流程图、零件图、表格等等。</p>
<h4 id="☆-执行细节"><a href="#☆-执行细节" class="headerlink" title="☆ 执行细节"></a><strong>☆ 执行细节</strong></h4><p>RL：5层金字塔，q=11，特征是10648维。图片二值化后，重排列至250K像素。该特征是独立于数据集的，因此可以运用到所有的任务中。</p>
<p>FV：基于5种尺度的SIFT特征，原始的SIFT特征通过PCA降维至77维，再联合位置等信息添加到80维。考虑不同大小的视觉词表。对于一个新的数据集，可以考虑新的SIFT-PCA和GMM来建立FV，也可以使用旧的模型。</p>
<p>混合：RL+MLP，FV+MLP。不同尺寸的FV需要不同的混合模型。</p>
<p>CNN：两种结构的网络，初始化过程可以在线获得。使用ImageNet2012预训练的网络，其效果要好于通过数据集训练的网络。因此我们选择预训练好的网络，再对其根据数据集进行调整。</p>
<h3 id="★-实验"><a href="#★-实验" class="headerlink" title="★ 实验"></a><strong>★ 实验</strong></h3><p>实验分为两个部分，第一部分是使用RVL-CDIP数据集进行分类实验，第二部分是测试特征迁移到其它数据集的新任务上的表现。</p>
<h4 id="☆-第一部分"><a href="#☆-第一部分" class="headerlink" title="☆ 第一部分"></a><strong>☆ 第一部分</strong></h4><p><img src="http://static.zybuluo.com/jiangshuo1016/2hvs84xachi6nt6dediko9x4/image_1cul732tnp7va741e1ihetap9.png" alt="image_1cul732tnp7va741e1ihetap9.png-18.4kB"></p>
<p>在RVL-CDIP数据集上进行分类实验，每一种特征的实验都选择最佳的参数，结果准确率如表格中所示。首先可以看到，CNN的两种结构要好于另外的特征，其中CNN-G达到了SOTA。其次FV+MLP的混合特征，性能已经接近于CNN，而它训练速度快且不需要使用GPU。相比单纯的RL和FV，结合MLP可以明显地提升其性能。另外，本实验再次佐证了FV要好于RL。</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/rpselsu5ko0jaj0in354b7g9/image_1cul8fs9r1e2i6tvm681nche9826.png" alt="image_1cul8fs9r1e2i6tvm681nche9826.png-13.5kB"></p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/kr4ixm5xcnnnfmmktdpl5jq8/image_1cul8gu2b16go1pl113vv7rj78833.png" alt="image_1cul8gu2b16go1pl113vv7rj78833.png-25.7kB"></p>
<p>每个特征的实验中，还比较了参数选择对性能的影响，包括：FV的词表大小的选择，MLP隐藏层数以及PCA降维与否。实验发现，FV16与FV256要好于FV4；隐藏层数与PCA降维对FV的影响不大。</p>
<h4 id="☆-第二部分"><a href="#☆-第二部分" class="headerlink" title="☆ 第二部分"></a><strong>☆ 第二部分</strong></h4><p>这部分主要是探索如何将第一部分得到的特征应用于新的数据集以及新的任务。</p>
<p><strong>※深层特征</strong></p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/0iv6mie7p64fb8pgyivbmxun/image_1cul8hmb81um1vvttabbl71lg63t.png" alt="image_1cul8hmb81um1vvttabbl71lg63t.png-80.8kB"></p>
<p>检索任务：测试了MAP，P@1，P@5。由于它们表现相似，所以表格里仅仅列出了MAP指标。CNN-G普遍要比CNN-A好；CNN-A-p5要好于CNN-A-fc6和fc7，可能是由于类别仅有16个。</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/iaapd704xvdufi7vaxtxedds/image_1cul8lf0eiq31ih5l881s8ce7p6p.png" alt="image_1cul8lf0eiq31ih5l881s8ce7p6p.png-32.6kB"></p>
<p>聚类任务：以调整互信息（AMI）为指标，越大意味着聚类与真实情况越吻合。使用层次聚类法对它们进行聚类。CNN-G普遍要比CNN-A好。</p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/lrthiebolbjpbt8du4w87frw/image_1cul8mm9n572jd13rh1kep1rp176.png" alt="image_1cul8mm9n572jd13rh1kep1rp176.png-33.3kB"></p>
<p>分类任务：使用NCM分类器，它不依赖参数。本可以选用kNN分类器，但是k=1时，其结果就于检索相同，因此没有选择。CNN-G与CNN-A相似。</p>
<p><strong>※浅层特征</strong></p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/lhnx2heg1qzhv4utnbe6vn5y/image_1cul8n58rkj9jt21o5lq0r18eq7j.png" alt="image_1cul8n58rkj9jt21o5lq0r18eq7j.png-71.3kB"></p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/fyxvb850nq5cb39hfs236d24/QQ%E6%88%AA%E5%9B%BE20181214113653.png" alt="QQ截图20181214113653.png-61.2kB"></p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/dl4zi7coh7mtnv0vf0u4d74g/image_1culcqdsta32rdi1mcnbbt1tciac.png" alt="image_1culcqdsta32rdi1mcnbbt1tciac.png-71.5kB"></p>
<p>在三项任务中，FV256+MLP在多数的数据集中总是表现最好，而PCA步骤会使性能稍稍降低。</p>
<p><strong>※对比</strong></p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/woe3i4r8osbfr75o29pzj3xm/image_1culd9cvbf5l1aa51s663gj1038ap.png" alt="image_1culd9cvbf5l1aa51s663gj1038ap.png-144.7kB"></p>
<p><strong>针对CLEF-IP数据集进行分析：FV256+PCA要好于CNN，可能有以下两点原因：图片的尺寸各异，使得CNN表示不能很好地适应所有的图片；类内的差异大，从整体的布局不能很好地得到类别。</strong></p>
<p><img src="http://static.zybuluo.com/jiangshuo1016/4rjhepod2lylsd7d3hlrn38y/image_1culdiui5rao96kbsr1o5r1f0b6.png" alt="image_1culdiui5rao96kbsr1o5r1f0b6.png-150.2kB"><br><img src="http://static.zybuluo.com/jiangshuo1016/g2edu6rn2cddwrzrfyjl94xz/image_1culdok9q87a8q11t7rdfq1k6hc0.png" alt="image_1culdok9q87a8q11t7rdfq1k6hc0.png-69.5kB"></p>
<p>这张图是随机选取图片作为相似检索，紫色框表示输入，上方（左）是FV256+PCA给出的结果，下方（右）是CNN-G-i4e给出的结果。绿色框表示相关，红色框表示不相关。</p>
<h3 id="★-总结"><a href="#★-总结" class="headerlink" title="★ 总结"></a><strong>★ 总结</strong></h3><p>这篇文章为对比三种文档图像表示方法提出了详细的基准，三种图像表示方法分别是：浅层特征（RL/FV)，深层特征（CNN-A,CNN-G），混合特征。实验首先对比了这些特征在同一个数据集上进行分类任务的表现，然后再在不同的数据集和任务上进行实验，以测试它们的泛化能力。</p>
<p>实验结果显示，在不涉及领域迁移的情况下，CNN特征的表现最好，紧随其后的是混合特征，而且混合特征能够节省很多的训练损耗。这在自然图片中已经得到了证明，我们将结论推向了文档图像。在领域迁移中，混合特征的表现远不如浅层特征和深层特征。对于CNN而言，它可以适应于训练时任务差不多的目标任务，且在布局信息重要的数据集表现较好。而FV-PCA在图片尺寸差异较大、类内差异较大的数据集中表现得更好。</p>
<p><strong>自己的收获：</strong></p>
<ol>
<li>深入学习了Fisher Vector的数学基础。</li>
<li>对文档图像的特征表示，有了全局的认识。</li>
<li>CLEF-IP数据集的表示，更适合选用FV-PCA特征。</li>
<li>CLEF-IP数据集的检索实验，可以通过紫框绿框红框这种方式，可视化呈现结果。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.png"
                alt="Jiang Shuo" />
            
              <p class="site-author-name" itemprop="name">Jiang Shuo</p>
              <p class="site-description motion-element" itemprop="description">SJTU | PhD Candidate</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:jsmech@sjtu.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://instagram.com/shuo0571" target="_blank" title="Instagram">
                      
                        <i class="fa fa-fw fa-instagram"></i>Instagram</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.linkedin.com/in/%E6%9C%94-%E5%A7%9C-743155159/" target="_blank" title="Linkedin">
                      
                        <i class="fa fa-fw fa-linkedin"></i>Linkedin</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="/uploads/wechat-QR2.jpg" target="_blank" title="个人微信">
                      
                        <i class="fa fa-fw fa-wechat"></i>个人微信</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jiang Shuo</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>





    <br>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
	<span id="busuanzi_container_page_pv">本文总阅读量<span id="busuanzi_value_page_pv"></span>次</span>



        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
